#!/usr/bin/env python3
"""
ì˜ìƒ ë¶„ì„ ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
"""

import asyncio
import logging
from src.clients.llm_provider import create_llm_provider
import google.generativeai as genai

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

async def debug_video_analysis():
    """ì˜ìƒ ë¶„ì„ ë””ë²„ê¹…"""
    
    print("ğŸ” ì˜ìƒ ë¶„ì„ ë””ë²„ê¹…")
    print("=" * 50)
    
    # í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤
    video_id = "Bq_znt--GTU"
    youtube_url = f"https://youtube.com/watch?v={video_id}"
    
    print(f"ğŸ¥ í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤: {video_id}")
    print(f"ğŸ”— YouTube URL: {youtube_url}")
    
    try:
        # LLM Provider ìƒì„±
        llm_provider = create_llm_provider()
        print(f"âœ… LLM Provider: {llm_provider.provider_name}")
        
        # Google API í‚¤ í™•ì¸
        settings = llm_provider.settings
        print(f"ğŸ”‘ Google API Key ì„¤ì •ë¨: {bool(settings.google_api_key and settings.google_api_key != '')}")
        print(f"ğŸ”‘ API Key ì• 10ì: {settings.google_api_key[:10] if settings.google_api_key else 'None'}...")
        
        # ì˜ìƒ ë¶„ì„ ëª¨ë¸ í™•ì¸
        if hasattr(llm_provider, 'video_analysis_model'):
            print(f"âœ… ì˜ìƒ ë¶„ì„ ëª¨ë¸ ìˆìŒ: {type(llm_provider.video_analysis_model)}")
        else:
            print("âŒ ì˜ìƒ ë¶„ì„ ëª¨ë¸ ì—†ìŒ")
            return
        
        # ì§ì ‘ Gemini API í…ŒìŠ¤íŠ¸
        print("\nğŸ§ª ì§ì ‘ Gemini API í…ŒìŠ¤íŠ¸...")
        
        try:
            # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
            simple_prompt = "ì´ YouTube ë¹„ë””ì˜¤ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            
            print(f"ğŸ“ í”„ë¡¬í”„íŠ¸: {simple_prompt}")
            print("â³ Gemini API í˜¸ì¶œ ì¤‘...")
            
            response = llm_provider.video_analysis_model.generate_content([
                genai.protos.Part(
                    file_data=genai.protos.FileData(
                        file_uri=youtube_url
                    )
                ),
                genai.protos.Part(text=simple_prompt)
            ])
            
            print("âœ… Gemini API ì‘ë‹µ ë°›ìŒ!")
            
            if hasattr(response, 'text') and response.text:
                print(f"ğŸ“„ ì‘ë‹µ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(response.text)} ë¬¸ì")
                print(f"ğŸ“„ ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 200ì):")
                print("-" * 40)
                print(response.text[:200])
                if len(response.text) > 200:
                    print("...")
                print("-" * 40)
            else:
                print("âš ï¸ ì‘ë‹µ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì—†ìŒ")
                print(f"ğŸ“Š ì‘ë‹µ ê°ì²´: {response}")
                
                # ì‘ë‹µ ê°ì²´ì˜ ì†ì„±ë“¤ í™•ì¸
                print("ğŸ” ì‘ë‹µ ê°ì²´ ì†ì„±ë“¤:")
                for attr in dir(response):
                    if not attr.startswith('_'):
                        try:
                            value = getattr(response, attr)
                            print(f"   {attr}: {type(value)} = {value}")
                        except:
                            print(f"   {attr}: (ì ‘ê·¼ ë¶ˆê°€)")
            
        except Exception as e:
            print(f"âŒ ì§ì ‘ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            print(f"âŒ ì—ëŸ¬ íƒ€ì…: {type(e)}")
            logger.exception("Direct API call failed")
        
        # LLM Provider ë©”ì„œë“œ í…ŒìŠ¤íŠ¸
        print("\nğŸ§ª LLM Provider ë©”ì„œë“œ í…ŒìŠ¤íŠ¸...")
        try:
            result = await llm_provider.analyze_youtube_video(video_id, "quick")
            print(f"ğŸ“Š LLM Provider ê²°ê³¼: {result}")
        except Exception as e:
            print(f"âŒ LLM Provider ë©”ì„œë“œ ì‹¤íŒ¨: {e}")
            logger.exception("LLM Provider method failed")
            
    except Exception as e:
        print(f"âŒ ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        logger.exception("Overall test failed")

if __name__ == "__main__":
    asyncio.run(debug_video_analysis())